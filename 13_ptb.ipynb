{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2178f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68d5c355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokens: ['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim']\n",
      "924412\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load Data\n",
    "def load_ptb_data(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    return text\n",
    "\n",
    "# Load train, validation, and test datasets\n",
    "train_text = load_ptb_data(\"ptbdataset/ptb.train.txt\")\n",
    "valid_text = load_ptb_data(\"ptbdataset/ptb.valid.txt\")\n",
    "\n",
    "# Step 2: Tokenization\n",
    "tokenizer = get_tokenizer(\"basic_english\")  # Use simple space-based tokenization\n",
    "train_tokens = tokenizer(train_text)\n",
    "valid_tokens = tokenizer(valid_text)\n",
    "\n",
    "print(\"Sample tokens:\", train_tokens[:20])  # Print first 20 tokens\n",
    "print(len(train_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42a31c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 9925\n",
      "Sample encoded data: [9895, 9896, 9897, 9899, 9900, 9901, 9905, 9906, 9907, 9908, 9909, 9911, 9912, 9913, 9914, 9916, 9917, 9918, 9919, 9920]\n"
     ]
    }
   ],
   "source": [
    "# Function to yield tokens for vocab building\n",
    "def yield_tokens(data):\n",
    "    for sentence in data:\n",
    "        yield sentence\n",
    "\n",
    "# Build vocabulary\n",
    "vocab = build_vocab_from_iterator(yield_tokens([train_tokens]), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])  # Set default unknown word index\n",
    "\n",
    "# Convert words to indices\n",
    "train_data = [vocab[word] for word in train_tokens]\n",
    "valid_data = [vocab[word] for word in valid_tokens]\n",
    "\n",
    "print(\"Vocabulary size:\", len(vocab))\n",
    "print(\"Sample encoded data:\", train_data[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b610a355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: torch.Size([924402, 10]) torch.Size([924402])\n",
      "First Training Sample (Input-Output):\n",
      "tensor([9895, 9896, 9897, 9899, 9900, 9901, 9905, 9906, 9907, 9908]) → tensor(9909)\n"
     ]
    }
   ],
   "source": [
    "# Choose sequence length\n",
    "SEQ_LENGTH = 10  # Modify if needed\n",
    "\n",
    "# Create input-output sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(len(data) - seq_length):\n",
    "        inputs.append(data[i : i + seq_length])  # n words\n",
    "        targets.append(data[i + seq_length])  # next word\n",
    "\n",
    "    return torch.tensor(inputs), torch.tensor(targets)\n",
    "\n",
    "# Prepare training and validation data\n",
    "train_inputs, train_targets = create_sequences(train_data, SEQ_LENGTH)\n",
    "valid_inputs, valid_targets = create_sequences(valid_data, SEQ_LENGTH)\n",
    "\n",
    "print(\"Training data shape:\", train_inputs.shape, train_targets.shape)\n",
    "print(\"First Training Sample (Input-Output):\")\n",
    "print(train_inputs[0], \"→\", train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31906c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([924402, 10])\n",
      "torch.Size([924402])\n"
     ]
    }
   ],
   "source": [
    "print(train_inputs.shape)\n",
    "print(train_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc2bdf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super(RNNLanguageModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)  # Word embeddings\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)  # LSTM layer\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)  # Fully connected layer\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)  # Convert word indices to embeddings\n",
    "        output, hidden = self.lstm(x, hidden)  # LSTM forward pass\n",
    "        output = self.fc(output[:, -1, :])  # Get the last output word\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f76ebb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNLanguageModel(\n",
      "  (embedding): Embedding(9925, 128)\n",
      "  (lstm): LSTM(128, 256, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=9925, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model Parameters\n",
    "vocab_size = len(vocab)  # Number of unique words\n",
    "embed_size = 128  # Size of word embedding vectors\n",
    "hidden_size = 256  # Hidden layer size in LSTM\n",
    "num_layers = 2  # Number of LSTM layers\n",
    "\n",
    "# Instantiate Model\n",
    "model = RNNLanguageModel(vocab_size, embed_size, hidden_size, num_layers)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1ed125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "140db943",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64  # You can adjust this\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = TensorDataset(train_inputs, train_targets)\n",
    "valid_dataset = TensorDataset(valid_inputs, valid_targets)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "626ec225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.11012101173400879\n",
      "1590.587893486023\n",
      "1000 28.195038080215454\n",
      "379054.09195041656\n",
      "2000 56.06177115440369\n",
      "697632.6802453995\n",
      "3000 83.73736500740051\n",
      "958290.4051446915\n",
      "4000 111.24383687973022\n",
      "1161830.6323719025\n",
      "5000 138.84261298179626\n",
      "1311229.637000084\n",
      "6000 169.59124898910522\n",
      "1432028.5064640045\n",
      "7000 197.1857590675354\n",
      "1467850.7904987335\n",
      "8000 224.76765394210815\n",
      "1448402.762002945\n",
      "9000 252.44211792945862\n",
      "1374294.8900079727\n",
      "10000 280.1045379638672\n",
      "1244784.5667114258\n",
      "11000 307.8839921951294\n",
      "1060352.4691200256\n",
      "12000 335.46423983573914\n",
      "819874.6021585464\n",
      "13000 363.1853311061859\n",
      "524439.6181173325\n",
      "14000 391.71969389915466\n",
      "173923.54409122467\n",
      "Epoch 1/10, Loss: 4.8354\n",
      "0 0.04204082489013672\n",
      "607.2376747131348\n",
      "1000 27.87277579307556\n",
      "374721.59776210785\n",
      "2000 55.42137885093689\n",
      "689663.6384210587\n",
      "3000 83.14227294921875\n",
      "951480.1716308594\n",
      "4000 110.67712092399597\n",
      "1155911.850930214\n",
      "5000 137.99771976470947\n",
      "1303250.4654579163\n",
      "6000 165.4438018798828\n",
      "1397007.4630737305\n",
      "7000 192.9059338569641\n",
      "1435991.7716312408\n",
      "8000 220.39839577674866\n",
      "1420247.2623853683\n",
      "9000 250.69622778892517\n",
      "1364790.2640829086\n",
      "10000 279.0278537273407\n",
      "1239999.781964302\n",
      "11000 306.90366101264954\n",
      "1056976.208527565\n",
      "12000 335.1872639656067\n",
      "819197.6731319427\n",
      "13000 363.5499849319458\n",
      "524966.1782417297\n",
      "14000 391.20475602149963\n",
      "173694.91167354584\n",
      "Epoch 2/10, Loss: 4.5962\n",
      "0 0.04463386535644531\n",
      "644.6915512084961\n",
      "1000 28.111090898513794\n",
      "377925.50603961945\n",
      "2000 57.977688789367676\n",
      "721474.3592948914\n",
      "3000 91.76611876487732\n",
      "1050171.463145256\n",
      "4000 122.11193871498108\n",
      "1275337.0879392624\n",
      "5000 151.46074271202087\n",
      "1430395.2541723251\n",
      "6000 180.2659718990326\n",
      "1522165.8667154312\n",
      "7000 209.10493779182434\n",
      "1556577.1569223404\n",
      "8000 237.27775692939758\n",
      "1529017.865653038\n",
      "9000 265.8879270553589\n",
      "1447493.8748893738\n",
      "10000 294.000040769577\n",
      "1306536.1811800003\n",
      "11000 322.7648057937622\n",
      "1111601.991153717\n",
      "12000 350.81961965560913\n",
      "857403.1504383087\n",
      "13000 378.49343276023865\n",
      "546544.5169057846\n",
      "14000 406.45091581344604\n",
      "180464.20662117004\n",
      "Epoch 3/10, Loss: 4.4191\n",
      "0 0.04553484916687012\n",
      "657.705361366272\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# You can change this\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 19\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m hidden \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     14\u001b[0m     torch\u001b[38;5;241m.\u001b[39mzeros(num_layers, batch_size, hidden_size),\n\u001b[1;32m     15\u001b[0m     torch\u001b[38;5;241m.\u001b[39mzeros(num_layers, batch_size, hidden_size)\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Reset gradients\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m outputs, hidden \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)  \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[21], line 10\u001b[0m, in \u001b[0;36mRNNLanguageModel.forward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden):\n\u001b[1;32m      9\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)  \u001b[38;5;66;03m# Convert word indices to embeddings\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# LSTM forward pass\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(output[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])  \u001b[38;5;66;03m# Get the last output word\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output, hidden\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/rnn.py:879\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    876\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    882\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    883\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        t1 = time.time()\n",
    "        total_loss = 0\n",
    "\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            batch_size = inputs.size(0)  # Get current batch size\n",
    "\n",
    "            # Initialize hidden state for each batch\n",
    "            hidden = (\n",
    "                torch.zeros(num_layers, batch_size, hidden_size),\n",
    "                torch.zeros(num_layers, batch_size, hidden_size)\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "            outputs, hidden = model(inputs, hidden)  # Forward pass\n",
    "\n",
    "            loss = criterion(outputs, targets)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if i % 1000 == 0:\n",
    "                exec_time = time.time() - t1\n",
    "                print(i, exec_time)\n",
    "                print(exec_time * (len(train_loader) - i))\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "num_epochs = 10  # You can change this\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd94a676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14444\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8b74f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

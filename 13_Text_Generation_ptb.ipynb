{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2178f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "from torchtext.vocab import build_vocab_from_iterator, Vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e29b2069-bbfb-4085-81e6-568721d10195",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "68d5c355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_text  aer banknote be\n",
      "Sample tokens: ['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim']\n",
      "924412\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load Data\n",
    "def load_ptb_data(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    return text\n",
    "\n",
    "# Load train, validation, and test datasets\n",
    "train_text = load_ptb_data(\"data/ptbdataset/ptb.train.txt\")\n",
    "valid_text = load_ptb_data(\"data/ptbdataset/ptb.valid.txt\")\n",
    "\n",
    "print(\"train_text\", train_text[:16])\n",
    "\n",
    "# Step 2: Tokenization\n",
    "tokenizer = get_tokenizer(\"basic_english\")  # Use simple space-based tokenization\n",
    "train_tokens = tokenizer(train_text)\n",
    "valid_tokens = tokenizer(valid_text)\n",
    "\n",
    "print(\"Sample tokens:\", train_tokens[:20])  # Print first 20 tokens\n",
    "print(len(train_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "42a31c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 9925\n",
      "Sample data: ['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim']\n",
      "Sample encoded data: [9895, 9896, 9897, 9899, 9900, 9901, 9905, 9906, 9907, 9908, 9909, 9911, 9912, 9913, 9914, 9916, 9917, 9918, 9919, 9920]\n"
     ]
    }
   ],
   "source": [
    "# Function to yield tokens for vocab building\n",
    "def yield_tokens(data):\n",
    "    for word in data:  # Directly iterate over tokenized words\n",
    "        yield word\n",
    "\n",
    "\n",
    "# Build vocabulary\n",
    "vocab = build_vocab_from_iterator(yield_tokens([train_tokens]), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])  # Set default unknown word index\n",
    "\n",
    "# Convert words to indices\n",
    "train_data = [vocab[word] for word in train_tokens]\n",
    "valid_data = [vocab[word] for word in valid_tokens]\n",
    "\n",
    "print(\"Vocabulary size:\", len(vocab))\n",
    "print(\"Sample data:\", train_tokens[:20])\n",
    "print(\"Sample encoded data:\", train_data[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b610a355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: torch.Size([924402, 10]) torch.Size([924402])\n",
      "First Training Sample (Input-Output):\n",
      "tensor([9895, 9896, 9897, 9899, 9900, 9901, 9905, 9906, 9907, 9908]) → tensor(9909)\n"
     ]
    }
   ],
   "source": [
    "# Choose sequence length\n",
    "SEQ_LENGTH = 10  # Modify if needed\n",
    "\n",
    "# Create input-output sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(len(data) - seq_length):\n",
    "        inputs.append(data[i : i + seq_length])  # n words\n",
    "        targets.append(data[i + seq_length])  # next word\n",
    "\n",
    "    return torch.tensor(inputs), torch.tensor(targets)\n",
    "\n",
    "# Prepare training and validation data\n",
    "train_inputs, train_targets = create_sequences(train_data, SEQ_LENGTH)\n",
    "valid_inputs, valid_targets = create_sequences(valid_data, SEQ_LENGTH)\n",
    "\n",
    "print(\"Training data shape:\", train_inputs.shape, train_targets.shape)\n",
    "print(\"First Training Sample (Input-Output):\")\n",
    "print(train_inputs[0], \"→\", train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "31906c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9895, 9896, 9897, 9899, 9900, 9901, 9905, 9906, 9907, 9908]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[9895, 9896, 9897, 9899, 9900],\n",
       "         [9896, 9897, 9899, 9900, 9901],\n",
       "         [9897, 9899, 9900, 9901, 9905],\n",
       "         [9899, 9900, 9901, 9905, 9906],\n",
       "         [9900, 9901, 9905, 9906, 9907]]),\n",
       " tensor([9901, 9905, 9906, 9907, 9908]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data[:10])\n",
    "create_sequences(train_data[:10], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fc2bdf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super(RNNLanguageModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)  # Word embeddings\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)  # LSTM layer\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)  # Fully connected layer\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)  # Convert word indices to embeddings\n",
    "        output, hidden = self.lstm(x, hidden)  # LSTM forward pass\n",
    "        output = self.fc(output[:, -1, :])  # Get the last output word\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f76ebb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRULanguageModel(\n",
      "  (embedding): Embedding(9925, 128)\n",
      "  (gru): GRU(128, 256, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=9925, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GRULanguageModel(\n",
       "  (embedding): Embedding(9925, 128)\n",
       "  (gru): GRU(128, 256, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=9925, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Parameters\n",
    "vocab_size = len(vocab)  # Number of unique words\n",
    "embed_size = 128  # Size of word embedding vectors\n",
    "hidden_size = 256  # Hidden layer size in LSTM\n",
    "num_layers = 2  # Number of LSTM layers\n",
    "\n",
    "# Instantiate Model\n",
    "model = GRULanguageModel(vocab_size, embed_size, hidden_size, num_layers)\n",
    "print(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ed125a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "140db943",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64  # You can adjust this\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = TensorDataset(train_inputs, train_targets)\n",
    "valid_dataset = TensorDataset(valid_inputs, valid_targets)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers = 2)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "626ec225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 77940.1514\n",
      "Epoch 2/50, Loss: 68976.1961\n",
      "Epoch 3/50, Loss: 65271.0554\n",
      "Epoch 4/50, Loss: 62723.2176\n",
      "Epoch 5/50, Loss: 60863.7307\n",
      "Epoch 6/50, Loss: 55072.3285\n",
      "Epoch 7/50, Loss: 52264.0135\n",
      "Epoch 8/50, Loss: 50372.9776\n",
      "Epoch 9/50, Loss: 48798.6614\n",
      "Epoch 10/50, Loss: 47415.4384\n",
      "Epoch 11/50, Loss: 43053.4421\n",
      "Epoch 12/50, Loss: 41433.7395\n",
      "Epoch 13/50, Loss: 40343.5045\n",
      "Epoch 14/50, Loss: 39396.3313\n",
      "Epoch 15/50, Loss: 38527.7991\n",
      "Epoch 16/50, Loss: 35829.5808\n",
      "Epoch 17/50, Loss: 35020.2683\n",
      "Epoch 18/50, Loss: 34451.2026\n",
      "Epoch 19/50, Loss: 33944.1718\n",
      "Epoch 20/50, Loss: 33469.2601\n",
      "Epoch 21/50, Loss: 31953.4627\n",
      "Epoch 22/50, Loss: 31576.1621\n",
      "Epoch 23/50, Loss: 31296.9289\n",
      "Epoch 24/50, Loss: 31035.6337\n",
      "Epoch 25/50, Loss: 30784.1079\n",
      "Epoch 26/50, Loss: 29965.0254\n",
      "Epoch 27/50, Loss: 29793.5187\n",
      "Epoch 28/50, Loss: 29656.7355\n",
      "Epoch 29/50, Loss: 29524.0465\n",
      "Epoch 30/50, Loss: 29396.8537\n",
      "Epoch 31/50, Loss: 28959.5228\n",
      "Epoch 32/50, Loss: 28881.0280\n",
      "Epoch 33/50, Loss: 28813.8285\n",
      "Epoch 34/50, Loss: 28748.0849\n",
      "Epoch 35/50, Loss: 28684.9928\n",
      "Epoch 36/50, Loss: 28454.4102\n",
      "Epoch 37/50, Loss: 28417.8570\n",
      "Epoch 38/50, Loss: 28384.4600\n",
      "Epoch 39/50, Loss: 28351.9196\n",
      "Epoch 40/50, Loss: 28319.9410\n",
      "Epoch 41/50, Loss: 28199.1811\n",
      "Epoch 42/50, Loss: 28182.0162\n",
      "Epoch 43/50, Loss: 28165.3085\n",
      "Epoch 44/50, Loss: 28148.8595\n",
      "Epoch 45/50, Loss: 28132.5730\n",
      "Epoch 46/50, Loss: 28070.2358\n",
      "Epoch 47/50, Loss: 28061.5162\n",
      "Epoch 48/50, Loss: 28052.9445\n",
      "Epoch 49/50, Loss: 28044.3740\n",
      "Epoch 50/50, Loss: 28035.9450\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loss function & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "def train_model_with_scheduler(model, train_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Initialize hidden state for GRU (single tensor, not a tuple)\n",
    "            hidden = torch.zeros(num_layers, inputs.size(0), hidden_size).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs, hidden = model(inputs, hidden)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        scheduler.step()  # Adjust learning rate\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "train_model_with_scheduler(model, train_loader, criterion, optimizer, scheduler, num_epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fd94a676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.1006\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, valid_loader, criterion):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():  # No gradient calculation during evaluation\n",
    "        for inputs, targets in valid_loader:\n",
    "            batch_size = inputs.size(0)\n",
    "\n",
    "            # Move inputs & targets to GPU\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Initialize hidden state & move to GPU\n",
    "            hidden = torch.zeros(num_layers, inputs.size(0), hidden_size).to(device)\n",
    "\n",
    "            outputs, hidden = model(inputs, hidden)  # Forward pass\n",
    "            loss = criterion(outputs, targets)  # Compute loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(valid_loader)\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}\")\n",
    "\n",
    "evaluate_model(model, valid_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ca8b74f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Next Words: ['buy', 'know', 'put', 'call', 'take']\n"
     ]
    }
   ],
   "source": [
    "def predict_next_word(model, input_text, vocab, seq_length=10, top_k=5):\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize input text\n",
    "    input_tokens = tokenizer(input_text)\n",
    "    input_indices = [vocab[word] for word in input_tokens if word in vocab]\n",
    "\n",
    "    if len(input_indices) < seq_length:\n",
    "        # Pad with <pad> tokens\n",
    "        input_indices = [vocab[\"<pad>\"]] * (seq_length - len(input_indices)) + input_indices\n",
    "\n",
    "    # Convert to tensor & move to GPU\n",
    "    input_tensor = torch.tensor(input_indices[-seq_length:]).unsqueeze(0).to(device)\n",
    "\n",
    "    # Initialize hidden state & move to GPU\n",
    "    hidden = torch.zeros(num_layers, input_tensor.size(0), hidden_size).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output, hidden = model(input_tensor, hidden)\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)  # Convert to probabilities\n",
    "        top_words = torch.topk(probabilities, top_k)  # Get top-k predicted words\n",
    "\n",
    "    predicted_words = [list(vocab.get_itos())[i] for i in top_words.indices.squeeze().tolist()]\n",
    "    return predicted_words\n",
    "\n",
    "# Test the function\n",
    "test_sentence = \"I want to\"\n",
    "predicted_next_words = predict_next_word(model, test_sentence, vocab)\n",
    "print(f\"Predicted Next Words: {predicted_next_words}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

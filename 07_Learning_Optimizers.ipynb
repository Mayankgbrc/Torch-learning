{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05990c9d-a632-4164-972c-4f92054cfa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9d7b76c-2a1f-4b22-94cf-3454d0deeaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1535.,    3.,   15.]) tensor([297.6995,   0.7071,   7.9057])\n",
      "tensor([[-0.4535,  0.0000,  0.6325],\n",
      "        [ 0.2183,  1.4142,  0.0000],\n",
      "        [ 0.5543,  0.0000, -0.6325],\n",
      "        [ 1.1421,  0.0000, -1.2649],\n",
      "        [-1.4612, -1.4142,  1.2649]])\n"
     ]
    }
   ],
   "source": [
    "# house data (size sq ft, bedrooms, age)\n",
    "X = torch.tensor([\n",
    "    [1400, 3, 20],\n",
    "    [1600, 4, 15],\n",
    "    [1700, 3, 10],\n",
    "    [1875, 3, 5],\n",
    "    [1100, 2, 25]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Normalize the data (important for better training)\n",
    "X_mean, X_std = X.mean(dim=0), X.std(dim=0)\n",
    "print(X_mean, X_std)\n",
    "\n",
    "X_norm = (X - X_mean) / X_std  # Standardization\n",
    "print(X_norm)\n",
    "\n",
    "Y = torch.tensor([[245], [312], [279], [308], [199]], dtype=torch.float32)  # Prices in $1000s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6291fde-6b21-40da-9229-56b7596493c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousePriceNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HousePriceNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(3,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "558f50e0-8a5a-4ec3-9703-f95d0bc3c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "model = HousePriceNN()\n",
    "model1 = HousePriceNN()\n",
    "model2 = HousePriceNN()\n",
    "model3 = HousePriceNN()\n",
    "model4 = HousePriceNN()\n",
    "\n",
    "sgd = optim.SGD(model1.parameters(), lr = 0.01)\n",
    "momentum_sgd = optim.SGD(model2.parameters(), lr = 0.01, momentum = 0.9)\n",
    "adam = optim.Adam(model3.parameters(), lr = 0.01)\n",
    "rmsprop = optim.RMSprop(model4.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75bdb043-a1e1-4c94-991b-280354ec682a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20, loss: 34090.5234375\n",
      "epoch: 40, loss: 15137.5966796875\n",
      "epoch: 60, loss: 6756.50244140625\n",
      "epoch: 80, loss: 3033.2578125\n",
      "epoch: 100, loss: 1375.1597900390625\n",
      "0: SGD: Loss = 73738.2656\n",
      "0: Momentum SGD: Loss = 73789.9062\n",
      "0: Adam: Loss = 74127.0000\n",
      "0: RMSprop: Loss = 74109.6875\n",
      "40: SGD: Loss = 14439.7549\n",
      "40: Momentum SGD: Loss = 217.9328\n",
      "40: Adam: Loss = 73835.4453\n",
      "40: RMSprop: Loss = 73264.7656\n",
      "80: SGD: Loss = 2894.0308\n",
      "80: Momentum SGD: Loss = 39.7863\n",
      "80: Adam: Loss = 73546.8516\n",
      "80: RMSprop: Loss = 72839.7344\n",
      "120: SGD: Loss = 607.1400\n",
      "120: Momentum SGD: Loss = 35.6121\n",
      "120: Adam: Loss = 73261.3281\n",
      "120: RMSprop: Loss = 72487.2344\n",
      "160: SGD: Loss = 151.3872\n",
      "160: Momentum SGD: Loss = 34.7928\n",
      "160: Adam: Loss = 72978.8203\n",
      "160: RMSprop: Loss = 72168.0469\n",
      "200: SGD: Loss = 59.9659\n",
      "200: Momentum SGD: Loss = 34.2301\n",
      "200: Adam: Loss = 72699.2578\n",
      "200: RMSprop: Loss = 71867.7109\n",
      "240: SGD: Loss = 41.3708\n",
      "240: Momentum SGD: Loss = 33.6882\n",
      "240: Adam: Loss = 72422.5781\n",
      "240: RMSprop: Loss = 71579.2891\n",
      "280: SGD: Loss = 37.4529\n",
      "280: Momentum SGD: Loss = 33.1639\n",
      "280: Adam: Loss = 72148.7188\n",
      "280: RMSprop: Loss = 71298.9688\n",
      "320: SGD: Loss = 36.5471\n",
      "320: Momentum SGD: Loss = 32.6569\n",
      "320: Adam: Loss = 71877.6328\n",
      "320: RMSprop: Loss = 71024.5312\n",
      "360: SGD: Loss = 36.2826\n",
      "360: Momentum SGD: Loss = 32.1663\n",
      "360: Adam: Loss = 71609.2188\n",
      "360: RMSprop: Loss = 70754.5938\n",
      "399: SGD: Loss = 36.1674\n",
      "399: Momentum SGD: Loss = 31.7035\n",
      "399: Adam: Loss = 71350.0781\n",
      "399: RMSprop: Loss = 70494.8984\n"
     ]
    }
   ],
   "source": [
    "# Training step for one optimizer\n",
    "\n",
    "model = HousePriceNN()\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "for i in range(1, epochs + 1):\n",
    "    predictions = model(X_norm)\n",
    "\n",
    "    loss = loss_fn(predictions, Y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 20 == 0:\n",
    "        print(f\"epoch: {i}, loss: {loss}\")\n",
    "\n",
    "def train_step(optimizer, name, model, i):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_norm)\n",
    "    loss = loss_fn(y_pred, Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%40 == 0 or i==399:\n",
    "        print(f\"{i}: {name}: Loss = {loss.item():.4f}\")\n",
    "    return model\n",
    "\n",
    "# Try different optimizers\n",
    "for i in range(400):\n",
    "    model1 = train_step(sgd, \"SGD\", model1, i)\n",
    "    model2 = train_step(momentum_sgd, \"Momentum SGD\", model2, i)\n",
    "    model3 = train_step(adam, \"Adam\", model3, i)\n",
    "    model4 = train_step(rmsprop, \"RMSprop\", model4, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7718e4a-4551-4ea3-b1f5-603ddd990ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.BatchNorm1d(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "356086a8-1ff9-4e80-a9a5-107f70723b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Learning Rate: [0.1]\n",
      "Epoch 2, Learning Rate: [0.1]\n",
      "Epoch 3, Learning Rate: [0.1]\n",
      "Epoch 4, Learning Rate: [0.1]\n",
      "Epoch 5, Learning Rate: [0.1]\n",
      "Epoch 6, Learning Rate: [0.1]\n",
      "Epoch 7, Learning Rate: [0.1]\n",
      "Epoch 8, Learning Rate: [0.1]\n",
      "Epoch 9, Learning Rate: [0.1]\n",
      "Epoch 10, Learning Rate: [0.010000000000000002]\n",
      "Epoch 11, Learning Rate: [0.010000000000000002]\n",
      "Epoch 12, Learning Rate: [0.010000000000000002]\n",
      "Epoch 13, Learning Rate: [0.010000000000000002]\n",
      "Epoch 14, Learning Rate: [0.010000000000000002]\n",
      "Epoch 15, Learning Rate: [0.010000000000000002]\n",
      "Epoch 16, Learning Rate: [0.010000000000000002]\n",
      "Epoch 17, Learning Rate: [0.010000000000000002]\n",
      "Epoch 18, Learning Rate: [0.010000000000000002]\n",
      "Epoch 19, Learning Rate: [0.010000000000000002]\n",
      "Epoch 20, Learning Rate: [0.0010000000000000002]\n",
      "Epoch 21, Learning Rate: [0.0010000000000000002]\n",
      "Epoch 22, Learning Rate: [0.0010000000000000002]\n",
      "Epoch 23, Learning Rate: [0.0010000000000000002]\n",
      "Epoch 24, Learning Rate: [0.0010000000000000002]\n",
      "Epoch 25, Learning Rate: [0.0010000000000000002]\n",
      "Epoch 26, Learning Rate: [0.0010000000000000002]\n",
      "Epoch 27, Learning Rate: [0.0010000000000000002]\n",
      "Epoch 28, Learning Rate: [0.0010000000000000002]\n",
      "Epoch 29, Learning Rate: [0.0010000000000000002]\n",
      "Epoch 30, Learning Rate: [0.00010000000000000003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayankgupta/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Simple model without BatchNorm\n",
    "class NoBatchNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(3, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.fc(x))\n",
    "\n",
    "x = torch.randn(100, 3)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)  # Initial LR = 0.1\n",
    "\n",
    "# Using StepLR\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "model = NoBatchNorm()\n",
    "\n",
    "for epoch in range(30):  \n",
    "    model(x)  # Your training loop\n",
    "    scheduler.step()  # Update learning rate\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Learning Rate: {scheduler.get_last_lr()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72bacacb-259c-447e-8c3b-1a569ac368b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Learning Rate: [0.09000000000000001]\n",
      "Epoch 2, Learning Rate: [0.08100000000000002]\n",
      "Epoch 3, Learning Rate: [0.07290000000000002]\n",
      "Epoch 4, Learning Rate: [0.06561000000000002]\n",
      "Epoch 5, Learning Rate: [0.05904900000000002]\n",
      "Epoch 6, Learning Rate: [0.05314410000000002]\n",
      "Epoch 7, Learning Rate: [0.04782969000000002]\n",
      "Epoch 8, Learning Rate: [0.043046721000000024]\n",
      "Epoch 9, Learning Rate: [0.03874204890000002]\n",
      "Epoch 10, Learning Rate: [0.03486784401000002]\n"
     ]
    }
   ],
   "source": [
    "# Optimizer with initial learning rate = 0.1\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "for epoch in range(10):\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Learning Rate: {scheduler.get_last_lr()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6647b05-d319-447f-947b-b9101d45a801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Learning Rate: [0.1], loss: 1.0\n",
      "Epoch 2, Learning Rate: [0.1], loss: 0.5\n",
      "Epoch 3, Learning Rate: [0.1], loss: 0.3333333333333333\n",
      "Epoch 4, Learning Rate: [0.1], loss: 0.3333333333333333\n",
      "Epoch 5, Learning Rate: [0.1], loss: 0.3333333333333333\n",
      "Epoch 6, Learning Rate: [0.1], loss: 0.3333333333333333\n",
      "Epoch 7, Learning Rate: [0.05], loss: 0.3333333333333333\n",
      "Epoch 8, Learning Rate: [0.05], loss: 0.3333333333333333\n",
      "Epoch 9, Learning Rate: [0.05], loss: 0.3333333333333333\n",
      "Epoch 10, Learning Rate: [0.05], loss: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "for epoch in range(10):\n",
    "    if epoch < 3:\n",
    "        loss = 1.0 / (epoch + 1)  # Simulated decreasing loss\n",
    "    else:\n",
    "        loss = loss\n",
    "    scheduler.step(loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Learning Rate: {scheduler.get_last_lr()}, loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea5a375-5b1e-416f-bf28-821ab2638fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

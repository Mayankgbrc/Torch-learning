{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b5d3c20-38ba-40cc-a6eb-a8bdd54d3f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb1ee2ea-780b-445c-8fbb-0336232b2055",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(root = \"./data\", download = True, train = True, transform = torchvision.transforms.ToTensor())\n",
    "test_data = torchvision.datasets.MNIST(root = \"./data\", download = True, train = False, transform = torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4776afd3-2d17-4132-84fc-1983bca36c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de1c051b-8a53-4eba-aca1-dc5447a5597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_batches = DataLoader(train_data, batch_size = 8, shuffle = True)\n",
    "test_data_batches = DataLoader(test_data, batch_size = 8, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "28b1451a-df00-45b1-9caf-f80d8189838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        self.layer1 = nn.Linear(28 * 28, 392)\n",
    "        self.bc1 = nn.BatchNorm1d(392)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.layer2 = nn.Linear(392, 128)\n",
    "        self.bc2 = nn.BatchNorm1d(128)\n",
    "        self.layer3 = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.bc1(x)\n",
    "        x = F.relu(x)\n",
    "        # x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "        x = self.bc2(x)\n",
    "        x = F.relu(x)\n",
    "        # x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f1b8ae09-6701-4989-9192-7d8e2761afa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x72debd54fa00>\n",
      "epoch: 0, loss: 0.08451491594314575\n",
      "epoch: 1, loss: 0.0033451940398663282\n",
      "epoch: 2, loss: 0.29710081219673157\n",
      "epoch: 3, loss: 0.036811575293540955\n",
      "epoch: 4, loss: 0.8894553780555725\n",
      "epoch: 5, loss: 0.04256376251578331\n",
      "epoch: 6, loss: 0.06969285756349564\n",
      "epoch: 7, loss: 0.027622731402516365\n",
      "epoch: 8, loss: 0.01625262014567852\n",
      "epoch: 9, loss: 0.000624795735348016\n",
      "Time Taken: 170.801913022995\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "model = MNISTClassifier()\n",
    "print(model.parameters())\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_x, batch_y in train_data_batches:\n",
    "        y = model(batch_x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(y, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    print(f\"epoch: {epoch}, loss: {loss}\")\n",
    "\n",
    "print(\"Time Taken:\", time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2e352d38-d715-4da6-8265-5fe686b6d88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.44 1.135613203048706\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "def show_batch(batch):\n",
    "    im = torchvision.utils.make_grid(batch)\n",
    "    plt.imshow(np.transpose(im.numpy(), (1, 2, 0)))\n",
    "\n",
    "def calculate_accuracy(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_data_batches:\n",
    "            # images = images.view(images.size(0), -1)\n",
    "            y = model(batch_x)\n",
    "            _, pred_val = torch.max(y, 1)\n",
    "            # show_batch(batch_x)\n",
    "\n",
    "            total += batch_y.size(0)  # Total number of labels\n",
    "            correct += (pred_val == batch_y).sum().item()\n",
    "            \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "t1 = time.time()\n",
    "accuracy_perc = calculate_accuracy(model, test_data_batches)\n",
    "print(accuracy_perc, time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d609b4a3-268b-4ff3-bab6-2a5e9dc333d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Normal - 97.44, time: 84 sec approx\n",
    "# Accuracy Batch Normalisation: 96.12\n",
    "# Accuracy Dropout: 97.18\n",
    "# Accuracy Batch and Dropout: 94.59\n",
    "# Accuracy Dropout and Batch: 94.96\n",
    "#MAX: 97.83, 97.76"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
